# -*- coding: utf-8 -*-
"""experiment_baselines.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YapvRqMllOupHVLdEDErOtf--9vx15PP
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install transformers

from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, precision_recall_fscore_support
from sklearn.model_selection import train_test_split
from transformers import (AutoTokenizer,
                          AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback)
import torch
import pandas as pd
import numpy as np
import os
from sklearn.metrics import confusion_matrix
os.environ["WANDB_DISABLED"] = "true"

no_train_epochs = 20
tokenizer = AutoTokenizer.from_pretrained('distilroberta-base')
model = AutoModelForSequenceClassification.from_pretrained('distilroberta-base', num_labels=2)

# Create torch dataset
class Dataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels=None):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        if self.labels:
            item["labels"] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.encodings["input_ids"])


def compute_metrics(p):
    pred, labels = p
    pred = np.argmax(pred, axis=1)

    print(confusion_matrix(labels, pred))

    accuracy = accuracy_score(y_true=labels, y_pred=pred)
    recall = recall_score(y_true=labels, y_pred=pred)
    precision = precision_score(y_true=labels, y_pred=pred)
    f1 = f1_score(y_true=labels, y_pred=pred)

    return {"accuracy": accuracy, "precision": precision, "recall": recall, "f1": f1}

df_input = pd.read_csv(r"/content/debateforum_train.csv")
df_input = df_input.sample(frac=1)

text = list(df_input['text'])
label = list(df_input['label'])

text_train, text_val, label_train, label_val = train_test_split(text, label, test_size=0.2)
text_train_tokenized = tokenizer(text_train, padding=True, truncation=True, max_length=512)
text_val_tokenized = tokenizer(text_val, padding=True, truncation=True, max_length=512)

train_dataset = Dataset(text_train_tokenized, label_train)
val_dataset = Dataset(text_val_tokenized, label_val)

# Define Trainer
args = TrainingArguments(
    output_dir="output",
    evaluation_strategy="epoch",
    logging_strategy="epoch",
    eval_steps=100,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=no_train_epochs,
    seed=0,

)
trainer = Trainer(
    model=model,
    args=args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],
)

model_path = "/content/drive/MyDrive/Thesis/fine_tuned_model_baseline_" + str(no_train_epochs) + "_epochs"

'''for param in model.roberta.parameters():
    param.requires_grad = False'''

trainer.train()
trainer.save_model(model_path)

model_path = "/content/drive/MyDrive/Thesis/fine_tuned_model_baseline_" + str(no_train_epochs) + "_epochs"

model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2)
# Create torch dataset
df_test = pd.read_csv(r"/content/debateforum_test.csv")
#df_test = df_test.sample(frac=1)

text_test = list(df_test['text'])
label_test = list(df_test['label'])

text_test_tokenized = tokenizer(text_test, padding=True, truncation=True, max_length=200)
test_dataset = Dataset(text_test_tokenized)

# Load trained model


# Define test trainer
test_trainer = Trainer(model)

# Make prediction
raw_pred, _, _ = test_trainer.predict(test_dataset)

# Preprocess raw predictions
y_pred = np.argmax(raw_pred, axis=1)

print("Testing done")
print(type(y_pred))
print("Confusion Matrix:")
print(confusion_matrix(label_test, y_pred))

test_accuracy = accuracy_score(y_true=label_test, y_pred=y_pred)
test_recall = recall_score(y_true=label_test, y_pred=y_pred)
test_precision = precision_score(y_true=label_test, y_pred=y_pred)
test_f1 = f1_score(y_true=label_test, y_pred=y_pred)

print("Test scores")
print("Accuracy: {}\nF1: {}\nPrecision: {}\nRecall: {}\n".format(test_accuracy, test_f1, test_precision, test_recall))

y_pred_list = list(y_pred)

data_for_df = {'text': text_test, 'orig_label': label_test, 'pred_label': y_pred}
df = pd.DataFrame(data_for_df)
df.to_csv('final_predictions_baseline_test_afp.csv')